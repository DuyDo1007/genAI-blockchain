import os
import sys
import streamlit as st
import pandas as pd
import joblib
import json
import numpy as np
from sentence_transformers import SentenceTransformer

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from src.rag_qa import retrieve, compose_prompt

MODEL_META_IF = 'models/trained_if.pkl'
EMB_MODEL = 'sentence-transformers/all-MiniLM-L6-v2'

st.set_page_config(
    page_title="GenAI Blockchain Security",
    page_icon="üîí",
    layout="wide"
)

st.sidebar.title("üîí GenAI Blockchain Security")
st.sidebar.markdown("---")
st.sidebar.markdown("### H·ªá th·ªëng ph√¢n t√≠ch v√† ph√°t hi·ªán l·ªó h·ªïng b·∫£o m·∫≠t trong Smart Contracts")
st.sidebar.markdown("---")
st.sidebar.markdown("**T√≠nh nƒÉng:**")
st.sidebar.markdown("- üì§ Upload v√† ph√¢n t√≠ch Smart Contract")
st.sidebar.markdown("- üí¨ RAG Q&A v·ªÅ b·∫£o m·∫≠t")
st.sidebar.markdown("- üîç Ph√°t hi·ªán b·∫•t th∆∞·ªùng (Anomaly Detection)")

st.title("üîí GenAI for Blockchain Security")
st.markdown("---")


tab1, tab2, tab3 = st.tabs(["üì§ Upload Contract", "üí¨ RAG Q&A", "üîç Anomaly Detection"])

with tab1:
    st.header("üì§ Upload Smart Contract")
    st.markdown("Upload file JSON ho·∫∑c CSV ch·ª©a smart contract ƒë·ªÉ ph√¢n t√≠ch")
    
    uploaded_file = st.file_uploader(
        "Ch·ªçn file JSON ho·∫∑c CSV",
        type=['json', 'csv'],
        help="Upload file ch·ª©a smart contract data"
    )
    
    if uploaded_file is not None:
        try:
            file_ext = uploaded_file.name.split('.')[-1].lower()
            
            if file_ext == 'json':
                data = json.load(uploaded_file)
                st.success("‚úì ƒê√£ t·∫£i file JSON th√†nh c√¥ng")
                if isinstance(data, dict):
                    st.subheader("Th√¥ng tin Contract:")
                    st.json(data)
                    if 'title' in data:
                        st.info(f"**Title:** {data['title']}")
                    if 'content' in data:
                        st.text_area("Content:", data['content'], height=200)
                    if 'impact' in data:
                        st.warning(f"**Impact:** {data['impact']}")
                elif isinstance(data, list):
                    st.success(f"‚úì ƒê√£ t·∫£i {len(data)} records")
                    df = pd.DataFrame(data)
                    st.dataframe(df)
                    
            elif file_ext == 'csv':
                df = pd.read_csv(uploaded_file)
                st.success(f"‚úì ƒê√£ t·∫£i file CSV th√†nh c√¥ng ({len(df)} rows)")
                st.dataframe(df.head(20))
                st.subheader("Th·ªëng k√™:")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("T·ªïng s·ªë records", len(df))
                with col2:
                    if 'impact' in df.columns:
                        st.metric("HIGH impact", df['impact'].str.upper().eq('HIGH').sum())
                with col3:
                    if 'vulnerability_label' in df.columns:
                        st.metric("Vulnerabilities", df['vulnerability_label'].notna().sum())
            
            if st.button("üîç Ph√¢n t√≠ch Contract", type="primary"):
                st.info("ƒêang ph√¢n t√≠ch... (T√≠nh nƒÉng n√†y c√≥ th·ªÉ ƒë∆∞·ª£c m·ªü r·ªông ƒë·ªÉ t√≠ch h·ª£p v·ªõi RAG v√† Anomaly Detection)")
                
        except Exception as e:
            st.error(f"‚ùå L·ªói khi ƒë·ªçc file: {str(e)}")
    else:
        st.info("üëÜ Vui l√≤ng upload file JSON ho·∫∑c CSV ƒë·ªÉ b·∫Øt ƒë·∫ßu")


with tab2:
    st.header("üí¨ RAG Q&A - H·ªèi ƒë√°p v·ªÅ Smart Contract Security")
    st.markdown("Nh·∫≠p c√¢u h·ªèi v·ªÅ b·∫£o m·∫≠t smart contract, h·ªá th·ªëng s·∫Ω t√¨m ki·∫øm v√† tr·∫£ l·ªùi d·ª±a tr√™n t√†i li·ªáu")
    
    index_path = 'data/processed/faiss_index.bin'
    meta_path = 'data/processed/metadf.parquet'
    
    if not os.path.exists(index_path) or not os.path.exists(meta_path):
        st.warning("‚ö†Ô∏è Vector store ch∆∞a ƒë∆∞·ª£c t·∫°o. Vui l√≤ng ch·∫°y `python src/ingest_to_vectorstore.py` tr∆∞·ªõc.")
    else:
        openai_key = st.text_input("OpenAI API Key:", type="password", help="Required for generating answers")
        
        col1, col2 = st.columns([3, 1])
        with col1:
            query = st.text_input(
                "Nh·∫≠p c√¢u h·ªèi:",
                placeholder="VD: What is reentrancy vulnerability? How to prevent it?",
                key="rag_query"
            )
        with col2:
            k = st.number_input("S·ªë documents (k):", min_value=1, max_value=10, value=3, step=1)
        
        st.markdown("**C√¢u h·ªèi m·∫´u:**")
        sample_queries = [
            "What is reentrancy vulnerability?",
            "How to prevent integer overflow in smart contracts?",
            "What are common access control issues?",
            "Explain unchecked external calls vulnerability"
        ]
        cols = st.columns(len(sample_queries))
        for i, sample_q in enumerate(sample_queries):
            with cols[i]:
                if st.button(f"üìå {sample_q[:30]}...", key=f"sample_{i}"):
                    query = sample_q
                    st.rerun()
        
        if st.button("üîç Truy v·∫•n RAG", type="primary", key="rag_search") and query and openai_key:
            try:
                from src.rag_qa import rag_query
                
                with st.spinner("ƒêang truy v·∫•n v√† t·∫°o c√¢u tr·∫£ l·ªùi..."):
                    result = rag_query(query, api_key=openai_key, k=k)
                
                st.success("‚úì T√¨m th·∫•y c√¢u tr·∫£ l·ªùi!")
                
                st.subheader("üìö Documents Retrieved:")
                for i, doc in enumerate(result['documents'], 1):
                    with st.expander(f"Document {i}: {doc['title']} (ID: {doc['id']})"):
                        st.text(doc['content'][:1000] + ('...' if len(doc['content']) > 1000 else ''))
                
                st.subheader("ü§ñ AI Answer:")
                st.markdown(result['answer'])
                    
            except Exception as e:
                st.error(f"‚ùå L·ªói: {str(e)}")
                st.info("ƒê·∫£m b·∫£o ƒë√£ ch·∫°y `python src/ingest_to_vectorstore.py` ƒë·ªÉ t·∫°o vector store.")
        elif st.button("‚ö†Ô∏è Ki·ªÉm tra l·ªói", type="secondary", key="rag_warning"):
            if not query:
                st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p c√¢u h·ªèi")
            if not openai_key:
                st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p OpenAI API Key")


with tab3:
    st.header("üîç Anomaly Detection - Ph√°t hi·ªán b·∫•t th∆∞·ªùng")
    st.markdown("Ph√°t hi·ªán c√°c smart contract findings b·∫•t th∆∞·ªùng ho·∫∑c ƒë√°ng nghi")
    
    st.info("üìä M√¥ h√¨nh: IsolationForest - Ph√°t hi·ªán anomalies d·ª±a tr√™n isolation trees")
    
    text_input = st.text_area(
        "Nh·∫≠p finding ho·∫∑c smart contract snippet:",
        placeholder="Paste finding text ho·∫∑c code snippet ƒë·ªÉ ki·ªÉm tra...",
        height=200
    )
    
    if st.button("üîç Ph√°t hi·ªán b·∫•t th∆∞·ªùng", type="primary") and text_input:
        try:
            if not os.path.exists(MODEL_META_IF):
                st.warning(f"‚ö†Ô∏è Model ch∆∞a ƒë∆∞·ª£c train. Vui l√≤ng ch·∫°y `python src/model_training.py` tr∆∞·ªõc.")
            else:
                with st.spinner("ƒêang ph√¢n t√≠ch..."):
                    meta = joblib.load(MODEL_META_IF)
                    clf = meta['clf']
                    emb_model_name = meta.get('emb_model_name', EMB_MODEL)
                    model = SentenceTransformer(emb_model_name)
                    
                    text_emb = model.encode([text_input], convert_to_numpy=True)
                    score = clf.decision_function(text_emb)[0]
                    prediction = clf.predict(text_emb)[0]
                    is_anomaly = prediction == -1
                    
                    st.subheader("üìä K·∫øt qu·∫£:")
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("Anomaly Score", f"{score:.4f}")
                    with col2:
                        if is_anomaly:
                            st.metric("K·∫øt qu·∫£", "‚ö†Ô∏è B·∫§T TH∆Ø·ªúNG", delta="Anomaly")
                        else:
                            st.metric("K·∫øt qu·∫£", "‚úì B√åNH TH∆Ø·ªúNG", delta="Normal")
                    
                    if is_anomaly:
                        st.error("‚ö†Ô∏è **Ph√°t hi·ªán b·∫•t th∆∞·ªùng!** Finding n√†y c√≥ th·ªÉ ch·ª©a l·ªó h·ªïng b·∫£o m·∫≠t nghi√™m tr·ªçng.")
                    else:
                        st.success("‚úì **B√¨nh th∆∞·ªùng** - Finding n√†y kh√¥ng c√≥ d·∫•u hi·ªáu b·∫•t th∆∞·ªùng.")
                    
                    st.info(f"""
                    **Gi·∫£i th√≠ch:**
                    - **Anomaly Score:** {score:.4f}
                    - Score < 0: B·∫•t th∆∞·ªùng (Anomaly)
                    - Score ‚â• 0: B√¨nh th∆∞·ªùng (Normal)
                    - Score c√†ng √¢m, m·ª©c ƒë·ªô b·∫•t th∆∞·ªùng c√†ng cao
                    """)
                    
        except Exception as e:
            st.error(f"‚ùå L·ªói: {str(e)}")
            st.info("ƒê·∫£m b·∫£o ƒë√£ train model tr∆∞·ªõc khi s·ª≠ d·ª•ng.")
    
    st.markdown("---")
    st.subheader("üì§ Batch Upload")
    batch_file = st.file_uploader("Upload file CSV ch·ª©a nhi·ªÅu findings:", type=['csv'])
    
    if batch_file is not None:
        try:
            df = pd.read_csv(batch_file)
            st.success(f"‚úì ƒê√£ t·∫£i {len(df)} findings")
            
            if st.button("üîç Ph√¢n t√≠ch t·∫•t c·∫£", type="primary"):
                if not os.path.exists(MODEL_META_IF):
                    st.warning("Model ch∆∞a ƒë∆∞·ª£c train.")
                else:
                    meta = joblib.load(MODEL_META_IF)
                    clf = meta['clf']
                    emb_model_name = meta.get('emb_model_name', EMB_MODEL)
                    model = SentenceTransformer(emb_model_name)
                    
                    texts = df['content'].fillna('').astype(str).tolist() if 'content' in df.columns else df.iloc[:, 0].astype(str).tolist()
                    embeddings = model.encode(texts, convert_to_numpy=True, show_progress_bar=True)
                    scores = clf.decision_function(embeddings)
                    predictions = clf.predict(embeddings)
                    
                    df['anomaly_score'] = scores
                    df['is_anomaly'] = (predictions == -1)
                    
                    st.dataframe(df[['anomaly_score', 'is_anomaly']].head(20))
                    st.success(f"Ph√°t hi·ªán {df['is_anomaly'].sum()} anomalies trong {len(df)} findings")
                    
        except Exception as e:
            st.error(f"L·ªói: {str(e)}")

st.markdown("---")
st.markdown("**GenAI for Blockchain Security** - H·ªá th·ªëng ph√¢n t√≠ch v√† ph√°t hi·ªán l·ªó h·ªïng b·∫£o m·∫≠t trong Smart Contracts")
"""
Streamlit Demo App cho GenAI Blockchain Security
3 tab: Upload Contract, RAG Q&A, Anomaly Detection
"""
import os
import sys
import streamlit as st
import pandas as pd
import joblib
import json
import numpy as np
from sentence_transformers import SentenceTransformer

# Fix import path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from src.rag_qa import retrieve, compose_prompt


MODEL_META_IF = 'models/trained_if.pkl'
MODEL_META_AE = 'models/autoencoder.h5'
EMB_MODEL = 'sentence-transformers/all-MiniLM-L6-v2'


# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="GenAI Blockchain Security",
    page_icon="üîí",
    layout="wide"
)


# Sidebar
st.sidebar.title("üîí GenAI Blockchain Security")
st.sidebar.markdown("---")
st.sidebar.markdown("### H·ªá th·ªëng ph√¢n t√≠ch v√† ph√°t hi·ªán l·ªó h·ªïng b·∫£o m·∫≠t trong Smart Contracts")
st.sidebar.markdown("---")
st.sidebar.markdown("**T√≠nh nƒÉng:**")
st.sidebar.markdown("- üì§ Upload v√† ph√¢n t√≠ch Smart Contract")
st.sidebar.markdown("- üí¨ RAG Q&A v·ªÅ b·∫£o m·∫≠t")
st.sidebar.markdown("- üîç Ph√°t hi·ªán b·∫•t th∆∞·ªùng (Anomaly Detection)")


# Main title
st.title("üîí GenAI for Blockchain Security")
st.markdown("---")


# Tabs
tab1, tab2, tab3 = st.tabs(["üì§ Upload Contract", "üí¨ RAG Q&A", "üîç Anomaly Detection"])


# Tab 1: Upload Contract
with tab1:
    st.header("üì§ Upload Smart Contract")
    st.markdown("Upload file JSON ho·∫∑c CSV ch·ª©a smart contract ƒë·ªÉ ph√¢n t√≠ch")
    
    uploaded_file = st.file_uploader(
        "Ch·ªçn file JSON ho·∫∑c CSV",
        type=['json', 'csv'],
        help="Upload file ch·ª©a smart contract data"
    )
    
    if uploaded_file is not None:
        try:
            file_ext = uploaded_file.name.split('.')[-1].lower()
            
            if file_ext == 'json':
                data = json.load(uploaded_file)
                st.success("‚úì ƒê√£ t·∫£i file JSON th√†nh c√¥ng")
                
                # Hi·ªÉn th·ªã th√¥ng tin
                if isinstance(data, dict):
                    st.subheader("Th√¥ng tin Contract:")
                    st.json(data)
                    
                    # Tr√≠ch xu·∫•t th√¥ng tin quan tr·ªçng
                    if 'title' in data:
                        st.info(f"**Title:** {data['title']}")
                    if 'content' in data:
                        st.text_area("Content:", data['content'], height=200)
                    if 'impact' in data:
                        st.warning(f"**Impact:** {data['impact']}")
                        
                elif isinstance(data, list):
                    st.success(f"‚úì ƒê√£ t·∫£i {len(data)} records")
                    df = pd.DataFrame(data)
                    st.dataframe(df)
                    
            elif file_ext == 'csv':
                df = pd.read_csv(uploaded_file)
                st.success(f"‚úì ƒê√£ t·∫£i file CSV th√†nh c√¥ng ({len(df)} rows)")
                st.dataframe(df.head(20))
                
                # Th·ªëng k√™
                st.subheader("Th·ªëng k√™:")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("T·ªïng s·ªë records", len(df))
                with col2:
                    if 'impact' in df.columns:
                        st.metric("HIGH impact", df['impact'].str.upper().eq('HIGH').sum())
                with col3:
                    if 'vulnerability_label' in df.columns:
                        st.metric("Vulnerabilities", df['vulnerability_label'].notna().sum())
            
            # N√∫t ph√¢n t√≠ch
            if st.button("üîç Ph√¢n t√≠ch Contract", type="primary"):
                st.info("ƒêang ph√¢n t√≠ch... (T√≠nh nƒÉng n√†y c√≥ th·ªÉ ƒë∆∞·ª£c m·ªü r·ªông ƒë·ªÉ t√≠ch h·ª£p v·ªõi RAG v√† Anomaly Detection)")
                
        except Exception as e:
            st.error(f"‚ùå L·ªói khi ƒë·ªçc file: {str(e)}")
    
    else:
        st.info("üëÜ Vui l√≤ng upload file JSON ho·∫∑c CSV ƒë·ªÉ b·∫Øt ƒë·∫ßu")


# Tab 2: RAG Q&A
with tab2:
    st.header("üí¨ RAG Q&A - H·ªèi ƒë√°p v·ªÅ Smart Contract Security")
    st.markdown("Nh·∫≠p c√¢u h·ªèi v·ªÅ b·∫£o m·∫≠t smart contract, h·ªá th·ªëng s·∫Ω t√¨m ki·∫øm v√† tr·∫£ l·ªùi d·ª±a tr√™n t√†i li·ªáu")
    
    # Ki·ªÉm tra vector store
    index_path = 'data/processed/faiss_index.bin'
    meta_path = 'data/processed/metadf.parquet'
    
    if not os.path.exists(index_path) or not os.path.exists(meta_path):
        st.warning("‚ö†Ô∏è Vector store ch∆∞a ƒë∆∞·ª£c t·∫°o. Vui l√≤ng ch·∫°y `python src/ingest_to_vectorstore.py` tr∆∞·ªõc.")
    else:
        # Input
        col1, col2 = st.columns([3, 1])
        with col1:
            query = st.text_input(
                "Nh·∫≠p c√¢u h·ªèi:",
                placeholder="VD: What is reentrancy vulnerability? How to prevent it?",
                key="rag_query"
            )
        with col2:
            k = st.number_input("S·ªë documents (k):", min_value=1, max_value=10, value=3, step=1)
        
        # C√¢u h·ªèi m·∫´u
        st.markdown("**C√¢u h·ªèi m·∫´u:**")
        sample_queries = [
            "What is reentrancy vulnerability?",
            "How to prevent integer overflow in smart contracts?",
            "What are common access control issues?",
            "Explain unchecked external calls vulnerability"
        ]
        cols = st.columns(len(sample_queries))
        for i, sample_q in enumerate(sample_queries):
            with cols[i]:
                if st.button(f"üìå {sample_q[:30]}...", key=f"sample_{i}"):
                    query = sample_q
                    st.rerun()
        
        if st.button("üîç Truy v·∫•n RAG", type="primary") and query:
            try:
                with st.spinner("ƒêang t√¨m ki·∫øm documents..."):
                    docs = retrieve(query, k=k)
                
                if docs:
                    st.success(f"‚úì T√¨m th·∫•y {len(docs)} documents li√™n quan")
                    
                    # Hi·ªÉn th·ªã documents
                    st.subheader("üìö Top Documents Retrieved:")
                    for i, doc in enumerate(docs, 1):
                        with st.expander(f"Document {i}: {doc['title']} (ID: {doc['id']})"):
                            st.markdown(f"**ID:** {doc['id']}")
                            st.markdown(f"**Title:** {doc['title']}")
                            st.markdown(f"**Content:**")
                            st.text(doc['content'][:1000] + ('...' if len(doc['content']) > 1000 else ''))
                    
                    # T·∫°o prompt
                    prompt = compose_prompt(query, docs)
                    
                    st.subheader("üìù Prompt cho LLM:")
                    st.code(prompt, language='text')
                    
                    # Copy button
                    st.info("üí° B·∫°n c√≥ th·ªÉ copy prompt tr√™n v√† s·ª≠ d·ª•ng v·ªõi OpenAI API ƒë·ªÉ nh·∫≠n c√¢u tr·∫£ l·ªùi chi ti·∫øt.")
                    
                    # T√πy ch·ªçn g·ªçi OpenAI API (n·∫øu c√≥)
                    if st.checkbox("S·ª≠ d·ª•ng OpenAI API ƒë·ªÉ generate answer"):
                        openai_key = st.text_input("OpenAI API Key:", type="password")
                        if openai_key and st.button("üöÄ Generate Answer"):
                            try:
                                import openai
                                openai.api_key = openai_key
                                
                                response = openai.ChatCompletion.create(
                                    model="gpt-3.5-turbo",
                                    messages=[
                                        {"role": "system", "content": "You are an expert in smart contract security."},
                                        {"role": "user", "content": prompt}
                                    ],
                                    temperature=0.7,
                                    max_tokens=500
                                )
                                
                                answer = response.choices[0].message.content
                                st.subheader("ü§ñ AI Answer:")
                                st.markdown(answer)
                            except Exception as e:
                                st.error(f"L·ªói khi g·ªçi OpenAI API: {str(e)}")
                else:
                    st.warning("Kh√¥ng t√¨m th·∫•y documents li√™n quan.")
                    
            except Exception as e:
                st.error(f"‚ùå L·ªói: {str(e)}")
                st.info("ƒê·∫£m b·∫£o ƒë√£ ch·∫°y `python src/ingest_to_vectorstore.py` ƒë·ªÉ t·∫°o vector store.")


# Tab 3: Anomaly Detection
with tab3:
    st.header("üîç Anomaly Detection - Ph√°t hi·ªán b·∫•t th∆∞·ªùng")
    st.markdown("Ph√°t hi·ªán c√°c smart contract findings b·∫•t th∆∞·ªùng ho·∫∑c ƒë√°ng nghi")
    
    # Ch·ªçn model
    model_type = st.radio(
        "Ch·ªçn model:",
        ["IsolationForest", "Autoencoder"],
        horizontal=True
    )
    
    # Input text
    text_input = st.text_area(
        "Nh·∫≠p finding ho·∫∑c smart contract snippet:",
        placeholder="Paste finding text ho·∫∑c code snippet ƒë·ªÉ ki·ªÉm tra...",
        height=200
    )
    
    if st.button("üîç Ph√°t hi·ªán b·∫•t th∆∞·ªùng", type="primary") and text_input:
        try:
            if model_type == "IsolationForest":
                if not os.path.exists(MODEL_META_IF):
                    st.warning(f"‚ö†Ô∏è Model ch∆∞a ƒë∆∞·ª£c train. Vui l√≤ng ch·∫°y `python src/model_training.py` tr∆∞·ªõc.")
                else:
                    with st.spinner("ƒêang ph√¢n t√≠ch..."):
                        # Load model
                        meta = joblib.load(MODEL_META_IF)
                        clf = meta['clf']
                        emb_model_name = meta.get('emb_model_name', EMB_MODEL)
                        model = SentenceTransformer(emb_model_name)
                        
                        # Encode text
                        text_emb = model.encode([text_input], convert_to_numpy=True)
                        
                        # Predict
                        score = clf.decision_function(text_emb)[0]
                        prediction = clf.predict(text_emb)[0]
                        is_anomaly = prediction == -1
                        
                        # Display results
                        st.subheader("üìä K·∫øt qu·∫£:")
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("Anomaly Score", f"{score:.4f}")
                        with col2:
                            if is_anomaly:
                                st.metric("K·∫øt qu·∫£", "‚ö†Ô∏è B·∫§T TH∆Ø·ªúNG", delta="Anomaly")
                            else:
                                st.metric("K·∫øt qu·∫£", "‚úì B√åNH TH∆Ø·ªúNG", delta="Normal")
                        
                        # Visualization
                        if is_anomaly:
                            st.error("‚ö†Ô∏è **Ph√°t hi·ªán b·∫•t th∆∞·ªùng!** Finding n√†y c√≥ th·ªÉ ch·ª©a l·ªó h·ªïng b·∫£o m·∫≠t nghi√™m tr·ªçng.")
                        else:
                            st.success("‚úì **B√¨nh th∆∞·ªùng** - Finding n√†y kh√¥ng c√≥ d·∫•u hi·ªáu b·∫•t th∆∞·ªùng.")
                        
                        # Explanation
                        st.info(f"""
                        **Gi·∫£i th√≠ch:**
                        - **Anomaly Score:** {score:.4f}
                        - Score < 0: B·∫•t th∆∞·ªùng (Anomaly)
                        - Score ‚â• 0: B√¨nh th∆∞·ªùng (Normal)
                        - Score c√†ng √¢m, m·ª©c ƒë·ªô b·∫•t th∆∞·ªùng c√†ng cao
                        """)
            
            elif model_type == "Autoencoder":
                if not os.path.exists(MODEL_META_AE):
                    st.warning(f"‚ö†Ô∏è Model ch∆∞a ƒë∆∞·ª£c train. Vui l√≤ng ch·∫°y `python src/model_training.py ae` tr∆∞·ªõc.")
                else:
                    try:
                        from tensorflow import keras
                        from sklearn.preprocessing import StandardScaler
                        
                        with st.spinner("ƒêang ph√¢n t√≠ch..."):
                            # Load model
                            autoencoder = keras.models.load_model(MODEL_META_AE)
                            meta_ae = joblib.load('models/autoencoder_meta.pkl')
                            scaler = meta_ae['scaler']
                            emb_model_name = meta_ae.get('emb_model_name', EMB_MODEL)
                            model = SentenceTransformer(emb_model_name)
                            
                            # Encode v√† predict
                            text_emb = model.encode([text_input], convert_to_numpy=True)
                            emb_scaled = scaler.transform(text_emb)
                            emb_pred = autoencoder.predict(emb_scaled, verbose=0)
                            
                            # T√≠nh reconstruction error
                            reconstruction_error = np.mean(np.square(emb_scaled - emb_pred))
                            threshold = np.percentile([reconstruction_error], 95)  # Simplified
                            is_anomaly = reconstruction_error > threshold
                            
                            # Display results
                            st.subheader("üìä K·∫øt qu·∫£:")
                            col1, col2 = st.columns(2)
                            with col1:
                                st.metric("Reconstruction Error", f"{reconstruction_error:.4f}")
                            with col2:
                                st.metric("Threshold", f"{threshold:.4f}")
                            
                            if is_anomaly:
                                st.error("‚ö†Ô∏è **Ph√°t hi·ªán b·∫•t th∆∞·ªùng!** Reconstruction error cao.")
                            else:
                                st.success("‚úì **B√¨nh th∆∞·ªùng** - Reconstruction error trong ng∆∞·ª°ng cho ph√©p.")
                                
                    except ImportError:
                        st.error("TensorFlow ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t. C·∫ßn: `pip install tensorflow`")
                    except Exception as e:
                        st.error(f"L·ªói: {str(e)}")
                        
        except Exception as e:
            st.error(f"‚ùå L·ªói: {str(e)}")
            st.info("ƒê·∫£m b·∫£o ƒë√£ train model tr∆∞·ªõc khi s·ª≠ d·ª•ng.")
    
    # Batch upload
    st.markdown("---")
    st.subheader("üì§ Batch Upload")
    batch_file = st.file_uploader("Upload file CSV ch·ª©a nhi·ªÅu findings:", type=['csv'])
    
    if batch_file is not None:
        try:
            df = pd.read_csv(batch_file)
            st.success(f"‚úì ƒê√£ t·∫£i {len(df)} findings")
            
            if st.button("üîç Ph√¢n t√≠ch t·∫•t c·∫£", type="primary"):
                if not os.path.exists(MODEL_META_IF):
                    st.warning("Model ch∆∞a ƒë∆∞·ª£c train.")
                else:
                    meta = joblib.load(MODEL_META_IF)
                    clf = meta['clf']
                    emb_model_name = meta.get('emb_model_name', EMB_MODEL)
                    model = SentenceTransformer(emb_model_name)
                    
                    # Process all
                    texts = df['content'].fillna('').astype(str).tolist() if 'content' in df.columns else df.iloc[:, 0].astype(str).tolist()
                    embeddings = model.encode(texts, convert_to_numpy=True, show_progress_bar=True)
                    scores = clf.decision_function(embeddings)
                    predictions = clf.predict(embeddings)
                    
                    df['anomaly_score'] = scores
                    df['is_anomaly'] = (predictions == -1)
                    
                    st.dataframe(df[['anomaly_score', 'is_anomaly']].head(20))
                    st.success(f"Ph√°t hi·ªán {df['is_anomaly'].sum()} anomalies trong {len(df)} findings")
                    
        except Exception as e:
            st.error(f"L·ªói: {str(e)}")


# Footer
st.markdown("---")
st.markdown("**GenAI for Blockchain Security** - H·ªá th·ªëng ph√¢n t√≠ch v√† ph√°t hi·ªán l·ªó h·ªïng b·∫£o m·∫≠t trong Smart Contracts")
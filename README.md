# GenAI for Blockchain Security

H·ªá th·ªëng ph√¢n t√≠ch v√† ph√°t hi·ªán l·ªó h·ªïng b·∫£o m·∫≠t trong Smart Contracts s·ª≠ d·ª•ng AI.

**Stack**: Sentence-Transformers + FAISS + IsolationForest + Streamlit + OpenAI API

## üéØ T√≠nh nƒÉng

### 1. **RAG Q&A** - H·ªèi ƒë√°p v·ªÅ Smart Contract Security

- Truy v·∫•n ki·∫øn th·ª©c t·ª´ 912 audit findings
- S·ª≠ d·ª•ng FAISS vector store ƒë·ªÉ t√¨m documents li√™n quan
- Generate c√¢u tr·∫£ l·ªùi b·∫±ng OpenAI API
- User ch·ªâ c·∫ßn nh·∫≠p API key

### 2. **Anomaly Detection** - Ph√°t hi·ªán b·∫•t th∆∞·ªùng

- Ph√°t hi·ªán findings b·∫•t th∆∞·ªùng trong smart contracts
- S·ª≠ d·ª•ng IsolationForest model (15% contamination)
- Anomaly Score: < 0 = anomaly, ‚â• 0 = normal
- H·ªó tr·ª£ batch processing

### 3. **Data Processing** - X·ª≠ l√Ω d·ªØ li·ªáu

- Chuy·ªÉn ƒë·ªïi 912 JSON files ‚Üí CSV
- Tr√≠ch xu·∫•t contract name, function name
- T·∫°o embeddings (384-dimensional)

## üìÅ C·∫•u tr√∫c

```
genai-blockchain-security/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                           # 912 JSON files
‚îÇ   ‚îî‚îÄ‚îÄ processed/
‚îÇ       ‚îú‚îÄ‚îÄ findings.csv               # Processed data
‚îÇ       ‚îú‚îÄ‚îÄ faiss_index.bin            # Vector store
‚îÇ       ‚îú‚îÄ‚îÄ metadf.parquet             # Metadata
‚îÇ       ‚îú‚îÄ‚îÄ evaluation_results.csv     # Model results
‚îÇ       ‚îî‚îÄ‚îÄ score_distribution.png     # Anomaly scores chart
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ trained_if.pkl                 # IsolationForest model
‚îÇ   ‚îî‚îÄ‚îÄ score_distribution.png         # Evaluation plot
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_data_exploration.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_data_preprocessing.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 03_model_training.ipynb
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ app.py                         # Streamlit UI (3 tabs)
‚îÇ   ‚îú‚îÄ‚îÄ data_preprocessing.py          # JSON ‚Üí CSV conversion
‚îÇ   ‚îú‚îÄ‚îÄ ingest_to_vectorstore.py       # Create FAISS index
‚îÇ   ‚îú‚îÄ‚îÄ model_training.py              # Train IsolationForest
‚îÇ   ‚îú‚îÄ‚îÄ evaluate_model.py              # Model evaluation
‚îÇ   ‚îú‚îÄ‚îÄ rag_qa.py                      # RAG functions
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ run_demo.sh                        # Auto run all steps
‚îî‚îÄ‚îÄ README.md
```

## üöÄ Quick Start

### 1. Setup

```bash
# Create virtual environment
python -m venv .venv

# Activate
# Linux/Mac:
source .venv/bin/activate
# Windows (Git Bash):
source .venv/Scripts/activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Run Full Pipeline

```bash
bash run_demo.sh
```

This will automatically:

- ‚úì Preprocess data (JSON ‚Üí CSV)
- ‚úì Create FAISS vector store
- ‚úì Train IsolationForest model
- ‚úì Evaluate model
- ‚úì Launch Streamlit app at http://localhost:8501

### 3. Or Run Individual Steps

```bash
# Step 1: Data preprocessing
python src/data_preprocessing.py

# Step 2: Create vector store
python src/ingest_to_vectorstore.py

# Step 3: Train model
python src/model_training.py

# Step 4: Evaluate model
python src/evaluate_model.py

# Step 5: Launch app
streamlit run src/app.py
```

## üìä Model Performance

**IsolationForest (contamination=0.15):**

- Anomalies Detected: 137/912 (15.02%)
- Precision: 0.0876
- Recall: 0.0828
- F1 Score: 0.0851
- Accuracy: 0.7171

**Anomaly Score Distribution:**

- Range: -0.0291 to 0.0548
- Mean: 0.0145
- Std: 0.0141
- Threshold: 0 (< 0 = anomaly)

## üé® Streamlit UI

### Tab 1: Upload Contract

- Upload JSON/CSV files
- Display contract info
- View statistics

### Tab 2: RAG Q&A (Full RAG)

- Enter OpenAI API key
- Ask questions about smart contract security
- Retrieve 1-10 documents
- Auto-generate answers
- View retrieved documents

### Tab 3: Anomaly Detection

- Single prediction: Paste finding text
- Batch prediction: Upload CSV file
- Get anomaly score and classification

## üíª Usage Examples

### RAG Q&A

```python
from src.rag_qa import rag_query

result = rag_query(
    query="What is reentrancy vulnerability?",
    api_key="sk-...",
    k=5
)

print(result['answer'])
print(result['documents'])
```

### Anomaly Detection

```python
import joblib
from sentence_transformers import SentenceTransformer

# Load model
meta = joblib.load('models/trained_if.pkl')
clf = meta['clf']
model = SentenceTransformer(meta['emb_model_name'])

# Predict
text = "Your finding text"
emb = model.encode([text], convert_to_numpy=True)
score = clf.decision_function(emb)[0]
is_anomaly = clf.predict(emb)[0] == -1

print(f"Score: {score:.4f}")
print(f"Anomaly: {is_anomaly}")
```

## üì¶ Technologies

| Component         | Library               | Version |
| ----------------- | --------------------- | ------- |
| Embeddings        | Sentence-Transformers | 2.7+    |
| Vector Store      | FAISS                 | 1.8+    |
| Anomaly Detection | scikit-learn          | 1.5+    |
| Web UI            | Streamlit             | 1.31+   |
| LLM Integration   | OpenAI                | 1.3+    |
| Data Processing   | pandas, numpy         | Latest  |

## ‚öôÔ∏è Configuration

### Embedding Model

- Model: `sentence-transformers/all-MiniLM-L6-v2`
- Dimensions: 384
- Speed: ~0.1ms per text

### IsolationForest Parameters

- contamination: 0.15 (15% expected anomalies)
- n_estimators: 100
- n_jobs: -1 (use all cores)

### FAISS Index

- Type: IndexFlatL2
- Distance metric: L2 (Euclidean)
- Search: O(n\*d) complexity

## üìù Data Format

**findings.csv** structure:

```
id          | title                          | content           | impact | ...
62000       | Reentrancy Vulnerability       | Description...    | HIGH   | ...
62001       | Integer Overflow in Transfer   | Description...    | MEDIUM | ...
```

## üîß Troubleshooting

**Issue**: Scores too close to 0

- **Solution**: Increase contamination in model_training.py (0.15 ‚Üí 0.2)

**Issue**: FAISS index not found

- **Solution**: Run `python src/ingest_to_vectorstore.py`

**Issue**: Model not trained

- **Solution**: Run `python src/model_training.py`

**Issue**: OpenAI API error

- **Solution**: Check API key, ensure it's valid and has quota

## üìà Performance

- **Training Time**: ~2 minutes
- **Prediction Time**: <100ms per text
- **Memory Usage**: ~500MB
- **Data Size**: 912 findings √ó 384 dimensions

## üìÑ Files

| File                           | Purpose                             |
| ------------------------------ | ----------------------------------- |
| `src/app.py`                   | Streamlit UI application            |
| `src/model_training.py`        | Train IsolationForest               |
| `src/evaluate_model.py`        | Evaluate model performance          |
| `src/rag_qa.py`                | RAG functions (retrieve + generate) |
| `src/ingest_to_vectorstore.py` | Create FAISS index                  |
| `src/data_preprocessing.py`    | Convert JSON to CSV                 |
| `requirements.txt`             | Python dependencies                 |
| `run_demo.sh`                  | Auto-run all steps                  |

## üéì Next Steps

1. **Improve Model**

   - Experiment with different contamination values
   - Try other anomaly detection algorithms
   - Add feature engineering

2. **Enhance RAG**

   - Implement prompt caching
   - Add response quality metrics
   - Fine-tune retrieval threshold

3. **Scale**
   - Use GPU acceleration for embeddings
   - Implement batch processing
   - Add API layer
